{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvioCOOFxEa1VZsMW1lisT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zetavg/LLM-Research/blob/main/LM_Tokenizer_Traditional_Chinese_Support_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LM Tokenizer Traditional Chinese Support Comparison\n",
        "\n",
        "Find out how the tokenizer of some language models treats Traditional Chinese."
      ],
      "metadata": {
        "id": "PrifrFnNwIBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ],
      "metadata": {
        "id": "KBpYEKAt7ubZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eSAsnKzwAiH",
        "outputId": "cd411749-98e9-43e7-8e74-3b713d9d44c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#@markdown Install dependencies and pre-download some tokenizers.\n",
        "!pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6b')\n",
        "AutoTokenizer.from_pretrained('EleutherAI/pythia-70m')\n",
        "AutoTokenizer.from_pretrained('bigscience/bloom')\n",
        "AutoTokenizer.from_pretrained('huggyllama/llama-7b')\n",
        "AutoTokenizer.from_pretrained('mosaicml/mpt-7b')\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper function for inspecting tokenize results of CJK characters\n",
        "\n",
        "Due to the nature of UTF-8 encoding, a single CJK character often got fragmented into multiple tokens by most tokenizers. This makes it challenging to understand how a sentence is tokenized by looking at the output. For instance:\n",
        "\n",
        "```python\n",
        ">>> tokenizer.tokenize('好')\n",
        "['å¥', '½']  # A single character divided into two tokens\n",
        "```\n",
        "\n",
        "```python\n",
        ">>> tokenizer.tokenize('你好世界！')\n",
        "['ä½', 'ł', 'å¥', '½', 'ä¸', 'ĸ', 'çķ', 'Į', 'ï', '¼', 'ģ']\n",
        "# ⬆ ???\n",
        "```\n",
        "\n",
        "To address this, here we write a function that tries to consolidate these fragmented tokens into complete CJK characters. It'll also annotates the number of tokens used to form each character, enabling us to gauge how well those CJK characters are supported."
      ],
      "metadata": {
        "id": "xQz6iv4WwbW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def consolidate_tokens_it(tokens, tokenizer):\n",
        "    processed_tokens = 0\n",
        "    i = 1\n",
        "    while i <= len(tokens):\n",
        "        possible_tokens_to_form_full_character = tokens[processed_tokens:i]\n",
        "        possible_full_character = tokenizer.convert_tokens_to_string(\n",
        "            possible_tokens_to_form_full_character)\n",
        "        if len(possible_full_character) > 1:\n",
        "            if len(possible_tokens_to_form_full_character) > 1:\n",
        "                # We got a token that should possibly belong to the next character.\n",
        "                # Yield with the last token removed.\n",
        "                tokens_to_form_full_character = \\\n",
        "                    possible_tokens_to_form_full_character[:-1]\n",
        "                full_character = tokenizer.convert_tokens_to_string(\n",
        "                    tokens_to_form_full_character\n",
        "                )\n",
        "                yield (full_character, len(tokens_to_form_full_character))\n",
        "            else:\n",
        "                # We only have one token, so this might be an English word.\n",
        "                # Yield it and start with the next token on the next iteration.\n",
        "                yield (\n",
        "                    possible_full_character,\n",
        "                    len(possible_tokens_to_form_full_character))\n",
        "                i += 1\n",
        "            # Set processed_tokens to the first token of the next character.\n",
        "            processed_tokens = i - 1\n",
        "        else:\n",
        "            # Try to add another token to the character on the next iteration.\n",
        "            i += 1\n",
        "    # If we have anything left, yield it.\n",
        "    remaining_tokens = tokens[processed_tokens:i]\n",
        "    if remaining_tokens:\n",
        "        yield (tokenizer.convert_tokens_to_string(remaining_tokens), len(remaining_tokens))\n",
        "\n",
        "\n",
        "def consolidate_tokens(tokens, tokenizer):\n",
        "    return list(consolidate_tokens_it(tokens, tokenizer))\n",
        "\n",
        "\n",
        "# Sample usage\n",
        "def print_tokenize_result(text, tokenizer):\n",
        "    tokenize_result = tokenizer.tokenize(text)\n",
        "    print(\"tokenize_result:\\n\", tokenize_result)\n",
        "    consolidated_tokenize_result = consolidate_tokens(\n",
        "        tokenize_result, tokenizer)\n",
        "    print(\"consolidated_tokenize_result:\\n\", consolidated_tokenize_result)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6b')\n",
        "print_tokenize_result('你好世界！', tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUcAfDJIwVQS",
        "outputId": "8bd998a0-fc39-4dfa-90c3-57e7afe52879"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenize_result:\n",
            " ['ä½', 'ł', 'å¥', '½', 'ä¸', 'ĸ', 'çķ', 'Į', 'ï', '¼', 'ģ']\n",
            "consolidated_tokenize_result:\n",
            " [('你', 2), ('好', 2), ('世', 2), ('界', 2), ('！', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define some sample text for testing\n",
        "sample_sentences = [\n",
        "    '網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。',\n",
        "    '人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。',\n",
        "    '程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。',\n",
        "]"
      ],
      "metadata": {
        "id": "k_6qLjlF70Ot"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_info_and_sample_results(tokenizer):\n",
        "    print(\"Tokenizer Class:\", tokenizer.__class__.__name__)\n",
        "    print(\"Vocab Size:\", tokenizer.vocab_size)\n",
        "    print()\n",
        "    for sample in sample_sentences:\n",
        "        print(\"sample:\", sample)\n",
        "        print_tokenize_result(sample, tokenizer)\n",
        "        print()"
      ],
      "metadata": {
        "id": "Y4K9PLmq8spM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizers"
      ],
      "metadata": {
        "id": "du7hnJRJ8cEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EleutherAI/gpt-j-6b\n",
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6b')\n",
        "print_info_and_sample_results(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HN9gpi9cwH",
        "outputId": "329c702c-c1bc-452e-cdb1-fc0a66ee502b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Class: GPT2TokenizerFast\n",
            "Vocab Size: 50257\n",
            "\n",
            "sample: 網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。\n",
            "tokenize_result:\n",
            " ['ç', '¶', '²', 'éļ', 'Ľ', 'ç', '¶', '²', 'è', '·', '¯', 'ï', '¼', 'Ī', 'è', 'ĭ', '±', 'èª', 'ŀ', 'ï', '¼', 'ļ', 'Internet', 'ï', '¼', 'ī', 'æĺ¯', 'æ', 'Į', 'ĩ', 'Ġ20', 'Ġ', 'ä¸', 'ĸ', 'ç', '´', 'Ģ', 'æľ', '«', 'æľ', 'Ł', 'èĪ', 'Īè', 'µ', '·', 'éĽ', '»', 'è', 'ħ', '¦', 'ç', '¶', '²', 'è', '·', '¯', 'èĪ', 'ĩ', 'éĽ', '»', 'è', 'ħ', '¦', 'ç', '¶', '²', 'è', '·', '¯', 'ä¹ĭ', 'éĸ', 'ĵ', 'æī', 'Ģ', 'ä¸', '²', 'éĢ', '£', 'æĪ', 'Ĳ', 'çļĦ', 'é¾', 'Ĳ', 'å¤§', 'ç', '¶', '²', 'è', '·', '¯', 'ç', '³', '»', 'ç', 'µ', '±', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('網', 3), ('際', 2), ('網', 3), ('路', 3), ('（', 3), ('英', 3), ('語', 2), ('：', 3), ('Internet', 1), ('）', 3), ('是', 1), ('指', 3), (' 20', 1), (' ', 1), ('世', 2), ('紀', 3), ('末', 2), ('期', 2), ('�', 1), ('��', 1), ('�', 1), ('�', 1), ('電', 2), ('腦', 3), ('網', 3), ('路', 3), ('與', 2), ('電', 2), ('腦', 3), ('網', 3), ('路', 3), ('之', 1), ('間', 2), ('所', 2), ('串', 2), ('連', 2), ('成', 2), ('的', 1), ('龐', 2), ('大', 1), ('網', 3), ('路', 3), ('系', 3), ('統', 3), ('。', 1)]\n",
            "\n",
            "sample: 人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。\n",
            "tokenize_result:\n",
            " ['äºº', 'å·', '¥', 'æ', 'Ļ', 'º', 'æ', 'ħ', '§', 'ï', '¼', 'Ī', 'è', 'ĭ', '±', 'èª', 'ŀ', 'ï', '¼', 'ļ', 'art', 'ificial', 'Ġintelligence', 'ï', '¼', 'Į', 'ç', '¸', '®', 'å¯', '«', 'ç', 'Ĥ', 'º', 'ĠAI', 'ï', '¼', 'ī', 'ï', '¼', 'Į', 'æĺ¯', 'æ', 'Į', 'ĩ', 'çĶ', '±', 'äºº', 'è£', '½', 'éĢ', 'ł', 'åĩ', 'º', 'ä', '¾', 'Ĩ', 'çļĦ', 'æ©Ł', 'å', 'Ļ', '¨', 'æī', 'Ģ', 'è¡', '¨', 'ç', 'ı', '¾', 'åĩ', 'º', 'ä', '¾', 'Ĩ', 'çļĦ', 'æ', 'Ļ', 'º', 'æ', 'ħ', '§', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('人', 1), ('工', 2), ('智', 3), ('慧', 3), ('（', 3), ('英', 3), ('語', 2), ('：', 3), ('art', 1), ('ificial', 1), (' intelligence', 1), ('，', 3), ('縮', 3), ('寫', 2), ('為', 3), (' AI', 1), ('）', 3), ('，', 3), ('是', 1), ('指', 3), ('由', 2), ('人', 1), ('製', 2), ('造', 2), ('出', 2), ('來', 3), ('的', 1), ('機', 1), ('器', 3), ('所', 2), ('表', 2), ('現', 3), ('出', 2), ('來', 3), ('的', 1), ('智', 3), ('慧', 3), ('。', 1)]\n",
            "\n",
            "sample: 程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。\n",
            "tokenize_result:\n",
            " ['ç', '¨', 'ĭ', 'å¼', 'ı', 'è', '¨', 'Ń', 'è', '¨', 'Ī', 'å¸', '«', 'å', 'Ģ', 'ĳ', 'è', '¶', 'Ĭ', 'ä', '¾', 'Ĩ', 'è', '¶', 'Ĭ', 'ä', '¾', 'Ŀ', 'è', '³', '´', 'ĠGit', 'Ġé', 'Ģ', '²', 'è¡', 'Į', 'çīĪ', 'æľ', '¬', 'æ', 'İ', '§', 'åĪ', '¶', 'ãĢģ', 'ä½¿', 'çĶ', '¨', 'ĠPython', 'ãĢģ', 'Ruby', 'Ġæ', 'Ī', 'ĸ', 'ĠJavaScript', 'Ġç', 'Ń', 'ī', 'ç', '¨', 'ĭ', 'å¼', 'ı', 'èª', 'ŀ', 'è', '¨', 'Ģ', 'éĸ', 'ĭ', 'ç', 'Ļ', '¼', 'ĠWeb', 'Ġæ', 'ĩ', 'ī', 'çĶ', '¨', 'ç', '¨', 'ĭ', 'å¼', 'ı', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('程', 3), ('式', 2), ('設', 3), ('計', 3), ('師', 2), ('們', 3), ('越', 3), ('來', 3), ('越', 3), ('依', 3), ('賴', 3), (' Git', 1), (' �', 1), ('�', 1), ('�', 1), ('行', 2), ('版', 1), ('本', 2), ('控', 3), ('制', 2), ('、', 1), ('使', 1), ('用', 2), (' Python', 1), ('、', 1), ('Ruby', 1), (' �', 1), ('�', 1), ('�', 1), (' JavaScript', 1), (' �', 1), ('�', 1), ('�', 1), ('程', 3), ('式', 2), ('語', 2), ('言', 3), ('開', 2), ('發', 3), (' Web', 1), (' �', 1), ('�', 1), ('�', 1), ('用', 2), ('程', 3), ('式', 2), ('。', 1)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "大多數中文字被拆成了兩個或以上的 token。"
      ],
      "metadata": {
        "id": "UhVlzK5ewqwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythia\n",
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/pythia-70m')\n",
        "print_info_and_sample_results(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWKmSDmXCarN",
        "outputId": "e8018a70-70b3-4e09-dca8-12e02347f71b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Class: GPTNeoXTokenizerFast\n",
            "Vocab Size: 50254\n",
            "\n",
            "sample: 網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。\n",
            "tokenize_result:\n",
            " ['ç¶', '²', 'éļ', 'Ľ', 'ç¶', '²', 'è·¯', 'ï¼Ī', 'èĭ', '±', 'èª', 'ŀ', 'ï¼ļ', 'Internet', 'ï¼ī', 'æĺ¯', 'æĮĩ', 'Ġ20', 'Ġ', 'ä¸ĸ', 'ç´', 'Ģ', 'æľ', '«', 'æľŁ', 'èĪ', 'Ī', 'èµ·', 'éĽ', '»', 'è', 'ħ', '¦', 'ç¶', '²', 'è·¯', 'èĪ', 'ĩ', 'éĽ', '»', 'è', 'ħ', '¦', 'ç¶', '²', 'è·¯', 'ä¹ĭ', 'éĸĵ', 'æīĢ', 'ä¸', '²', 'éĢ', '£', 'æĪĲ', 'çļĦ', 'é', '¾', 'Ĳ', 'å¤§', 'ç¶', '²', 'è·¯', 'ç³»', 'çµ', '±', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('網', 2), ('際', 2), ('網', 2), ('路', 1), ('（', 1), ('英', 2), ('語', 2), ('：', 1), ('Internet', 1), ('）', 1), ('是', 1), ('指', 1), (' 20', 1), (' ', 1), ('世', 1), ('紀', 2), ('末', 2), ('期', 1), ('興', 2), ('起', 1), ('電', 2), ('腦', 3), ('網', 2), ('路', 1), ('與', 2), ('電', 2), ('腦', 3), ('網', 2), ('路', 1), ('之', 1), ('間', 1), ('所', 1), ('串', 2), ('連', 2), ('成', 1), ('的', 1), ('龐', 3), ('大', 1), ('網', 2), ('路', 1), ('系', 1), ('統', 2), ('。', 1)]\n",
            "\n",
            "sample: 人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。\n",
            "tokenize_result:\n",
            " ['äºº', 'å·¥', 'æĻ', 'º', 'æħ', '§', 'ï¼Ī', 'èĭ', '±', 'èª', 'ŀ', 'ï¼ļ', 'art', 'ificial', 'Ġintelligence', 'ï¼Į', 'ç', '¸', '®', 'å¯', '«', 'çĤ', 'º', 'ĠAI', 'ï¼ī', 'ï¼Į', 'æĺ¯', 'æĮĩ', 'çĶ±', 'äºº', 'è£', '½', 'éĢ', 'ł', 'åĩº', 'ä¾', 'Ĩ', 'çļĦ', 'æ©Ł', 'åĻ¨', 'æīĢ', 'è¡¨', 'çı¾', 'åĩº', 'ä¾', 'Ĩ', 'çļĦ', 'æĻ', 'º', 'æħ', '§', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('人', 1), ('工', 1), ('智', 2), ('慧', 2), ('（', 1), ('英', 2), ('語', 2), ('：', 1), ('art', 1), ('ificial', 1), (' intelligence', 1), ('，', 1), ('縮', 3), ('寫', 2), ('為', 2), (' AI', 1), ('）', 1), ('，', 1), ('是', 1), ('指', 1), ('由', 1), ('人', 1), ('製', 2), ('造', 2), ('出', 1), ('來', 2), ('的', 1), ('機', 1), ('器', 1), ('所', 1), ('表', 1), ('現', 1), ('出', 1), ('來', 2), ('的', 1), ('智', 2), ('慧', 2), ('。', 1)]\n",
            "\n",
            "sample: 程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。\n",
            "tokenize_result:\n",
            " ['ç¨ĭ', 'å¼ı', 'è¨', 'Ń', 'è¨', 'Ī', 'å¸', '«', 'åĢ', 'ĳ', 'è¶', 'Ĭ', 'ä¾', 'Ĩ', 'è¶', 'Ĭ', 'ä¾', 'Ŀ', 'è³', '´', 'ĠGit', 'Ġ', 'éĢ', '²', 'è¡Į', 'çī', 'Ī', 'æľ¬', 'æİ', '§', 'åĪ¶', 'ãĢģ', 'ä½¿çĶ¨', 'ĠPython', 'ãĢģ', 'Ruby', 'Ġ', 'æĪĸ', 'ĠJavaScript', 'Ġ', 'çŃī', 'ç¨ĭ', 'å¼ı', 'èª', 'ŀ', 'è¨Ģ', 'éĸĭ', 'çĻ', '¼', 'ĠWeb', 'Ġ', 'æ', 'ĩ', 'ī', 'çĶ¨', 'ç¨ĭ', 'å¼ı', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('程', 1), ('式', 1), ('設', 2), ('計', 2), ('師', 2), ('們', 2), ('越', 2), ('來', 2), ('越', 2), ('依', 2), ('賴', 2), (' Git', 1), (' ', 1), ('進', 2), ('行', 1), ('版', 2), ('本', 1), ('控', 2), ('制', 1), ('、', 1), ('使用', 1), (' Python', 1), ('、', 1), ('Ruby', 1), (' ', 1), ('或', 1), (' JavaScript', 1), (' ', 1), ('等', 1), ('程', 1), ('式', 1), ('語', 2), ('言', 1), ('開', 1), ('發', 2), (' Web', 1), (' ', 1), ('應', 3), ('用', 1), ('程', 1), ('式', 1), ('。', 1)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title BLOOM\n",
        "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom')\n",
        "print_info_and_sample_results(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGGgGUCSE-rU",
        "outputId": "1b333e03-50cf-4270-e392-589964c509d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Class: BloomTokenizerFast\n",
            "Vocab Size: 250680\n",
            "\n",
            "sample: 網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。\n",
            "tokenize_result:\n",
            " ['ç¶²éļĽç¶²è·¯', 'ï¼Īèĭ±èªŀï¼ļ', 'Internet', 'ï¼īæĺ¯', 'æĮĩ', 'Ġ20', 'Ġ', 'ä¸ĸç´Ģ', 'æľ«æľŁ', 'èĪĪèµ·', 'éĽ»èħ¦', 'ç¶²è·¯', 'èĪĩ', 'éĽ»èħ¦', 'ç¶²è·¯', 'ä¹ĭéĸĵ', 'æīĢ', 'ä¸²', 'éĢ£', 'æĪĲçļĦ', 'é¾Ĳ', 'å¤§', 'ç¶²è·¯', 'ç³»çµ±', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('網際網路', 1), ('（英語：', 1), ('Internet', 1), ('）是', 1), ('指', 1), (' 20', 1), (' ', 1), ('世紀', 1), ('末期', 1), ('興起', 1), ('電腦', 1), ('網路', 1), ('與', 1), ('電腦', 1), ('網路', 1), ('之間', 1), ('所', 1), ('串', 1), ('連', 1), ('成的', 1), ('龐', 1), ('大', 1), ('網路', 1), ('系統', 1), ('。', 1)]\n",
            "\n",
            "sample: 人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。\n",
            "tokenize_result:\n",
            " ['äººå·¥', 'æĻºæħ§', 'ï¼Īèĭ±èªŀï¼ļ', 'art', 'ificial', 'Ġintelligence', 'ï¼Į', 'ç¸®å¯«', 'çĤº', 'ĠAI', 'ï¼ī', 'ï¼Į', 'æĺ¯æĮĩ', 'çĶ±', 'äºº', 'è£½éĢł', 'åĩºä¾ĨçļĦ', 'æ©ŁåĻ¨', 'æīĢ', 'è¡¨çı¾', 'åĩºä¾ĨçļĦ', 'æĻºæħ§', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('人工', 1), ('智慧', 1), ('（英語：', 1), ('art', 1), ('ificial', 1), (' intelligence', 1), ('，', 1), ('縮寫', 1), ('為', 1), (' AI', 1), ('）', 1), ('，', 1), ('是指', 1), ('由', 1), ('人', 1), ('製造', 1), ('出來的', 1), ('機器', 1), ('所', 1), ('表現', 1), ('出來的', 1), ('智慧', 1), ('。', 1)]\n",
            "\n",
            "sample: 程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。\n",
            "tokenize_result:\n",
            " ['ç¨ĭå¼ı', 'è¨Ńè¨Īå¸«', 'åĢĳ', 'è¶Ĭä¾Ĩè¶Ĭ', 'ä¾Ŀè³´', 'ĠGit', 'Ġ', 'éĢ²è¡Į', 'çīĪæľ¬', 'æİ§åĪ¶', 'ãĢģ', 'ä½¿çĶ¨', 'ĠPython', 'ãĢģ', 'Ruby', 'ĠæĪĸ', 'ĠJavaScript', 'ĠçŃī', 'ç¨ĭå¼ı', 'èªŀè¨Ģ', 'éĸĭçĻ¼', 'ĠWeb', 'Ġ', 'æĩīçĶ¨ç¨ĭå¼ı', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('程式', 1), ('設計師', 1), ('們', 1), ('越來越', 1), ('依賴', 1), (' Git', 1), (' ', 1), ('進行', 1), ('版本', 1), ('控制', 1), ('、', 1), ('使用', 1), (' Python', 1), ('、', 1), ('Ruby', 1), (' 或', 1), (' JavaScript', 1), (' 等', 1), ('程式', 1), ('語言', 1), ('開發', 1), (' Web', 1), (' ', 1), ('應用程式', 1), ('。', 1)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOOM 用了達 25 萬、其他模型五倍之大的 vocab size ，可以"
      ],
      "metadata": {
        "id": "GhlMhrA6I3O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LLaMA\n",
        "tokenizer = AutoTokenizer.from_pretrained('huggyllama/llama-7b')\n",
        "print_info_and_sample_results(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIiNcsFU8blh",
        "outputId": "1adc9c1f-7b14-43c2-d96a-1ee95a6799ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Class: LlamaTokenizerFast\n",
            "Vocab Size: 32000\n",
            "\n",
            "sample: 網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。\n",
            "tokenize_result:\n",
            " ['▁', '<0xE7>', '<0xB6>', '<0xB2>', '<0xE9>', '<0x9A>', '<0x9B>', '<0xE7>', '<0xB6>', '<0xB2>', '路', '（', '英', '語', '：', 'Internet', '）', '是', '指', '▁', '2', '0', '▁', '世', '紀', '<0xE6>', '<0x9C>', '<0xAB>', '期', '<0xE8>', '<0x88>', '<0x88>', '起', '電', '<0xE8>', '<0x85>', '<0xA6>', '<0xE7>', '<0xB6>', '<0xB2>', '路', '<0xE8>', '<0x88>', '<0x87>', '電', '<0xE8>', '<0x85>', '<0xA6>', '<0xE7>', '<0xB6>', '<0xB2>', '路', '之', '間', '所', '串', '連', '成', '的', '<0xE9>', '<0xBE>', '<0x90>', '大', '<0xE7>', '<0xB6>', '<0xB2>', '路', '系', '<0xE7>', '<0xB5>', '<0xB1>', '。']\n",
            "consolidated_tokenize_result:\n",
            " [('�', 2), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('路', 1), ('（', 1), ('英', 1), ('語', 1), ('：', 1), ('Internet', 1), ('）', 1), ('是', 1), ('指', 1), ('2', 2), ('0', 1), ('世', 2), ('紀', 1), ('�', 1), ('�', 1), ('�', 1), ('期', 1), ('�', 1), ('�', 1), ('�', 1), ('起', 1), ('電', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('路', 1), ('�', 1), ('�', 1), ('�', 1), ('電', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('路', 1), ('之', 1), ('間', 1), ('所', 1), ('串', 1), ('連', 1), ('成', 1), ('的', 1), ('�', 1), ('�', 1), ('�', 1), ('大', 1), ('�', 1), ('�', 1), ('�', 1), ('路', 1), ('系', 1), ('�', 1), ('�', 1), ('�', 1), ('。', 1)]\n",
            "\n",
            "sample: 人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。\n",
            "tokenize_result:\n",
            " ['▁', '人', '工', '智', '<0xE6>', '<0x85>', '<0xA7>', '（', '英', '語', '：', 'art', 'ific', 'ial', '▁intelligence', '，', '<0xE7>', '<0xB8>', '<0xAE>', '<0xE5>', '<0xAF>', '<0xAB>', '<0xE7>', '<0x82>', '<0xBA>', '▁A', 'I', '）', '，', '是', '指', '由', '人', '<0xE8>', '<0xA3>', '<0xBD>', '造', '出', '<0xE4>', '<0xBE>', '<0x86>', '的', '機', '器', '所', '表', '現', '出', '<0xE4>', '<0xBE>', '<0x86>', '的', '智', '<0xE6>', '<0x85>', '<0xA7>', '。']\n",
            "consolidated_tokenize_result:\n",
            " [('人', 2), ('工', 1), ('智', 1), ('�', 1), ('�', 1), ('�', 1), ('（', 1), ('英', 1), ('語', 1), ('：', 1), ('art', 1), ('ific', 1), ('ial', 1), ('intelligence', 1), ('，', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('A', 1), ('I', 1), ('）', 1), ('，', 1), ('是', 1), ('指', 1), ('由', 1), ('人', 1), ('�', 1), ('�', 1), ('�', 1), ('造', 1), ('出', 1), ('�', 1), ('�', 1), ('�', 1), ('的', 1), ('機', 1), ('器', 1), ('所', 1), ('表', 1), ('現', 1), ('出', 1), ('�', 1), ('�', 1), ('�', 1), ('的', 1), ('智', 1), ('�', 1), ('�', 1), ('�', 1), ('。', 1)]\n",
            "\n",
            "sample: 程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。\n",
            "tokenize_result:\n",
            " ['▁', '程', '式', '設', '計', '師', '<0xE5>', '<0x80>', '<0x91>', '越', '<0xE4>', '<0xBE>', '<0x86>', '越', '<0xE4>', '<0xBE>', '<0x9D>', '<0xE8>', '<0xB3>', '<0xB4>', '▁Git', '▁', '進', '行', '版', '本', '控', '制', '、', '使', '用', '▁Python', '、', 'R', 'uby', '▁', '或', '▁JavaScript', '▁', '等', '程', '式', '語', '言', '開', '<0xE7>', '<0x99>', '<0xBC>', '▁Web', '▁', '<0xE6>', '<0x87>', '<0x89>', '用', '程', '式', '。']\n",
            "consolidated_tokenize_result:\n",
            " [('程', 2), ('式', 1), ('設', 1), ('計', 1), ('師', 1), ('�', 1), ('�', 1), ('�', 1), ('越', 1), ('�', 1), ('�', 1), ('�', 1), ('越', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('�', 1), ('Git', 1), ('進', 2), ('行', 1), ('版', 1), ('本', 1), ('控', 1), ('制', 1), ('、', 1), ('使', 1), ('用', 1), ('Python', 1), ('、', 1), ('R', 1), ('uby', 1), ('或', 2), ('JavaScript', 1), ('等', 2), ('程', 1), ('式', 1), ('語', 1), ('言', 1), ('開', 1), ('�', 1), ('�', 1), ('�', 1), ('Web', 1), ('�', 2), ('�', 1), ('�', 1), ('用', 1), ('程', 1), ('式', 1), ('。', 1)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MPT-7b\n",
        "tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b')\n",
        "print_info_and_sample_results(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0c1wyRPFnL5",
        "outputId": "a48b51e6-eb4c-41fe-b127-46fd99dcc1b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Class: GPTNeoXTokenizerFast\n",
            "Vocab Size: 50254\n",
            "\n",
            "sample: 網際網路（英語：Internet）是指 20 世紀末期興起電腦網路與電腦網路之間所串連成的龐大網路系統。\n",
            "tokenize_result:\n",
            " ['ç¶', '²', 'éļ', 'Ľ', 'ç¶', '²', 'è·¯', 'ï¼Ī', 'èĭ', '±', 'èª', 'ŀ', 'ï¼ļ', 'Internet', 'ï¼ī', 'æĺ¯', 'æĮĩ', 'Ġ20', 'Ġ', 'ä¸ĸ', 'ç´', 'Ģ', 'æľ', '«', 'æľŁ', 'èĪ', 'Ī', 'èµ·', 'éĽ', '»', 'è', 'ħ', '¦', 'ç¶', '²', 'è·¯', 'èĪ', 'ĩ', 'éĽ', '»', 'è', 'ħ', '¦', 'ç¶', '²', 'è·¯', 'ä¹ĭ', 'éĸĵ', 'æīĢ', 'ä¸', '²', 'éĢ', '£', 'æĪĲ', 'çļĦ', 'é', '¾', 'Ĳ', 'å¤§', 'ç¶', '²', 'è·¯', 'ç³»', 'çµ', '±', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('網', 2), ('際', 2), ('網', 2), ('路', 1), ('（', 1), ('英', 2), ('語', 2), ('：', 1), ('Internet', 1), ('）', 1), ('是', 1), ('指', 1), (' 20', 1), (' ', 1), ('世', 1), ('紀', 2), ('末', 2), ('期', 1), ('興', 2), ('起', 1), ('電', 2), ('腦', 3), ('網', 2), ('路', 1), ('與', 2), ('電', 2), ('腦', 3), ('網', 2), ('路', 1), ('之', 1), ('間', 1), ('所', 1), ('串', 2), ('連', 2), ('成', 1), ('的', 1), ('龐', 3), ('大', 1), ('網', 2), ('路', 1), ('系', 1), ('統', 2), ('。', 1)]\n",
            "\n",
            "sample: 人工智慧（英語：artificial intelligence，縮寫為 AI），是指由人製造出來的機器所表現出來的智慧。\n",
            "tokenize_result:\n",
            " ['äºº', 'å·¥', 'æĻ', 'º', 'æħ', '§', 'ï¼Ī', 'èĭ', '±', 'èª', 'ŀ', 'ï¼ļ', 'art', 'ificial', 'Ġintelligence', 'ï¼Į', 'ç', '¸', '®', 'å¯', '«', 'çĤ', 'º', 'ĠAI', 'ï¼ī', 'ï¼Į', 'æĺ¯', 'æĮĩ', 'çĶ±', 'äºº', 'è£', '½', 'éĢ', 'ł', 'åĩº', 'ä¾', 'Ĩ', 'çļĦ', 'æ©Ł', 'åĻ¨', 'æīĢ', 'è¡¨', 'çı¾', 'åĩº', 'ä¾', 'Ĩ', 'çļĦ', 'æĻ', 'º', 'æħ', '§', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('人', 1), ('工', 1), ('智', 2), ('慧', 2), ('（', 1), ('英', 2), ('語', 2), ('：', 1), ('art', 1), ('ificial', 1), (' intelligence', 1), ('，', 1), ('縮', 3), ('寫', 2), ('為', 2), (' AI', 1), ('）', 1), ('，', 1), ('是', 1), ('指', 1), ('由', 1), ('人', 1), ('製', 2), ('造', 2), ('出', 1), ('來', 2), ('的', 1), ('機', 1), ('器', 1), ('所', 1), ('表', 1), ('現', 1), ('出', 1), ('來', 2), ('的', 1), ('智', 2), ('慧', 2), ('。', 1)]\n",
            "\n",
            "sample: 程式設計師們越來越依賴 Git 進行版本控制、使用 Python、Ruby 或 JavaScript 等程式語言開發 Web 應用程式。\n",
            "tokenize_result:\n",
            " ['ç¨ĭ', 'å¼ı', 'è¨', 'Ń', 'è¨', 'Ī', 'å¸', '«', 'åĢ', 'ĳ', 'è¶', 'Ĭ', 'ä¾', 'Ĩ', 'è¶', 'Ĭ', 'ä¾', 'Ŀ', 'è³', '´', 'ĠGit', 'Ġ', 'éĢ', '²', 'è¡Į', 'çī', 'Ī', 'æľ¬', 'æİ', '§', 'åĪ¶', 'ãĢģ', 'ä½¿çĶ¨', 'ĠPython', 'ãĢģ', 'Ruby', 'Ġ', 'æĪĸ', 'ĠJavaScript', 'Ġ', 'çŃī', 'ç¨ĭ', 'å¼ı', 'èª', 'ŀ', 'è¨Ģ', 'éĸĭ', 'çĻ', '¼', 'ĠWeb', 'Ġ', 'æ', 'ĩ', 'ī', 'çĶ¨', 'ç¨ĭ', 'å¼ı', 'ãĢĤ']\n",
            "consolidated_tokenize_result:\n",
            " [('程', 1), ('式', 1), ('設', 2), ('計', 2), ('師', 2), ('們', 2), ('越', 2), ('來', 2), ('越', 2), ('依', 2), ('賴', 2), (' Git', 1), (' ', 1), ('進', 2), ('行', 1), ('版', 2), ('本', 1), ('控', 2), ('制', 1), ('、', 1), ('使用', 1), (' Python', 1), ('、', 1), ('Ruby', 1), (' ', 1), ('或', 1), (' JavaScript', 1), (' ', 1), ('等', 1), ('程', 1), ('式', 1), ('語', 2), ('言', 1), ('開', 1), ('發', 2), (' Web', 1), (' ', 1), ('應', 3), ('用', 1), ('程', 1), ('式', 1), ('。', 1)]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}