{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOJLZPRgc5ZO/rwrVKdT6Hh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zetavg/LLM-Research/blob/main/MLQA_Dataset_Converter_(en_zh_tw).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLQA Dataset Converter (en-zh_tw)\n",
        "\n",
        "Converts the MLQA (MultiLingual Question Answering) dataset specifically for English and Traditional Chinese bilingual language models.\n",
        "\n",
        "Generated dataset on Hugging Face: https://huggingface.co/datasets/zetavg/mlqa_en_zh_tw.\n",
        "\n",
        "Sample:\n",
        "\n",
        "```json\n",
        "[\n",
        "  {\n",
        "    \"title\": {\n",
        "      \"zh_tw\": \"2014 年冬季奧林匹克運動會冰壺比賽\",\n",
        "      \"en\": \"Curling at the 2014 Winter Olympics\"\n",
        "    },\n",
        "    \"paragraphs\": [\n",
        "      {\n",
        "        \"context\": {\n",
        "          \"zh_tw\": \"本屆冬奧會冰壺比賽參加資格有兩種辦法可以取得。各國家或地區可以透過 2012 年和 2013 年的世界冰壺錦標賽，也可以透過 2013 年 12 月舉辦的一次冬奧會資格賽來取得資格。七個國家透過兩屆世錦賽積分之和來獲得資格，兩個國家則透過冬奧會資格賽。作為主辦國，俄羅斯自動獲得參賽資格，這樣就確定了冬奧會冰壺比賽的男女各十支參賽隊伍。\",\n",
        "          \"en\": \"Qualification to the curling tournaments at the Winter Olympics was determined through two methods. Nations could qualify teams by earning qualification points from performances at the 2012 and 2013 World Curling Championships. Teams could also qualify through an Olympic qualification event which was held in the autumn of 2013. Seven nations qualified teams via World Championship qualification points, while two nations qualified through the qualification event. As host nation, Russia qualified teams automatically, thus making a total of ten teams per gender in the curling tournaments.\"\n",
        "        },\n",
        "        \"qas\": [\n",
        "          {\n",
        "            \"id\": \"b08184972e38a79c47d01614aa08505bb3c9b680\",\n",
        "            \"question\": {\n",
        "              \"zh_tw\": \"俄羅斯有多少隊獲得參賽資格？\",\n",
        "              \"en\": \"How many teams did Russia qualify for?\"\n",
        "            },\n",
        "            \"answers\": {\n",
        "              \"zh_tw\": [\n",
        "                {\n",
        "                  \"text\": \"十支\",\n",
        "                  \"answer_start\": 161\n",
        "                }\n",
        "              ],\n",
        "              \"en\": [\n",
        "                {\n",
        "                  \"text\": \"ten teams\",\n",
        "                  \"answer_start\": 543\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Note that some data points may have some of the languages lacking in the title, context, questions or answers.\n"
      ],
      "metadata": {
        "id": "d5ccgm8iA3u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the 6 files obtained from [facebookresearch/MLQA](https://github.com/facebookresearch/mlqa) under `/content` (the default working directory):\n",
        "Ｓ\n",
        "* `dev-context-zh-question-zh.json`\n",
        "* `dev-context-zh-question-en.json`\n",
        "* `dev-context-en-question-zh.json`\n",
        "* `test-context-zh-question-zh.json`\n",
        "* `test-context-zh-question-en.json`\n",
        "* `test-context-en-question-zh.json`\n",
        "\n",
        "Converted and merged datasets will be saved under `/content/outputs`."
      ],
      "metadata": {
        "id": "A_-XnulygdgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rEGiPiS6NeY"
      },
      "outputs": [],
      "source": [
        "!pip install datasets opencc pangu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_json_file(file_name):\n",
        "    with open(file_name, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "zcx10N_LE-Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def print_json(*args):\n",
        "    print(*[\n",
        "        v if isinstance(v, str)\n",
        "        else json.dumps(v, indent=2, ensure_ascii=False)\n",
        "        for v in args\n",
        "    ])"
      ],
      "metadata": {
        "id": "1UF3qBLkFA2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Sample Data"
      ],
      "metadata": {
        "id": "UiUnZueQEfbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sample data in context-zh, question-zh version\n",
        "import json\n",
        "\n",
        "sample_zh_zh_data = load_json_file(\"dev-context-zh-question-zh.json\")['data']\n",
        "\n",
        "sample_zh_zh_data_item = sample_zh_zh_data[1]\n",
        "print_json(\"Sample item:\", sample_zh_zh_data_item)"
      ],
      "metadata": {
        "id": "QU4_ufX07vGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Find matching sample data other language versions\n",
        "\n",
        "def find_item_by_qa_id(data, qa_id):\n",
        "    for item in data:\n",
        "        for paragraph in item['paragraphs']:\n",
        "            for qa in paragraph['qas']:\n",
        "                if qa['id'] == qa_id:\n",
        "                    return item\n",
        "    return None\n",
        "\n",
        "sample_zh_en_data = load_json_file(\"dev-context-zh-question-en.json\")['data']\n",
        "sample_en_zh_data = load_json_file(\"dev-context-en-question-zh.json\")['data']\n",
        "\n",
        "sample_zh_en_data_item = find_item_by_qa_id(\n",
        "    sample_zh_en_data,\n",
        "    sample_zh_zh_data_item['paragraphs'][0]['qas'][0]['id']\n",
        ")\n",
        "print_json(\"Sample zh-en item:\", sample_zh_en_data_item)\n",
        "\n",
        "sample_en_zh_data_item = find_item_by_qa_id(\n",
        "    sample_en_zh_data,\n",
        "    sample_zh_zh_data_item['paragraphs'][0]['qas'][0]['id']\n",
        ")\n",
        "print_json(\"Sample en-zh item:\", sample_en_zh_data_item)"
      ],
      "metadata": {
        "id": "v9sLUlUYGW9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a Data Converter"
      ],
      "metadata": {
        "id": "l4orV3q3Fvzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Convert function for converting Simplified Chinese to Traditional Chinese and add spacing.\n",
        "\n",
        "import opencc\n",
        "import pangu\n",
        "s2twp_converter = opencc.OpenCC('s2twp.json')\n",
        "\n",
        "def convert(text):\n",
        "    text = s2twp_converter.convert(text)\n",
        "    text = pangu.spacing_text(text)\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "print(convert('互联网（英语称为Internet）是指20世纪末期兴起电脑网络与电脑网络之间所串连成的庞大网络系统。'))"
      ],
      "metadata": {
        "id": "Amf0-0Sj95tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Print a sample item to reference it's structure.\n",
        "print_json(sample_zh_zh_data_item)"
      ],
      "metadata": {
        "id": "nKvB6axXKbJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert an item (in-place!):"
      ],
      "metadata": {
        "id": "IbzJcajmKmuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_item(item,\n",
        "                 convert_contexts=True,\n",
        "                 convert_questions=True,\n",
        "                 convert_answers=True):\n",
        "    if convert_contexts:\n",
        "        item['title'] = convert(item['title'])\n",
        "\n",
        "    for paragraph in item['paragraphs']:\n",
        "        if convert_contexts:\n",
        "            original_context = paragraph['context']\n",
        "            paragraph['context'] = convert(paragraph['context'])\n",
        "\n",
        "        for qa in paragraph['qas']:\n",
        "            if convert_questions:\n",
        "                qa['question'] = convert(qa['question'])\n",
        "\n",
        "            if convert_contexts or convert_answers:\n",
        "                for answer in qa['answers']:\n",
        "                    if convert_contexts:\n",
        "                        # Need to update answer_start\n",
        "                        # if the context has been converted\n",
        "                        original_context_before_answer = \\\n",
        "                            original_context[:answer['answer_start']]\n",
        "                        converted_context_before_answer = \\\n",
        "                            convert(original_context_before_answer)\n",
        "                        answer['answer_start'] = \\\n",
        "                            len(converted_context_before_answer)\n",
        "\n",
        "                    if convert_answers:\n",
        "                        answer['text'] = convert(answer['text'])\n",
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "convert_item(sample_zh_zh_data_item)\n",
        "print_json(\"Converted zh-zh item\", sample_zh_zh_data_item)\n",
        "\n",
        "convert_item(sample_zh_en_data_item,\n",
        "             convert_questions=False)\n",
        "print_json(\"Converted zh-en item\", sample_zh_en_data_item)\n",
        "\n",
        "convert_item(sample_en_zh_data_item,\n",
        "             convert_contexts=False, convert_answers=False)\n",
        "print_json(\"Converted en-zh item\", sample_en_zh_data_item)\n"
      ],
      "metadata": {
        "id": "0YxnrMnt-HLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_items(items_list, **kwargs):\n",
        "    for item in items_list:\n",
        "        convert_item(item, **kwargs)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "\n",
        "convert_items(sample_zh_zh_data)\n",
        "# print_json(\"Converted zh-zh items\", sample_zh_zh_data[:2])\n",
        "\n",
        "convert_items(sample_zh_en_data,\n",
        "             convert_questions=False)\n",
        "# print_json(\"Converted zh-en items\", sample_zh_en_data[:2])\n",
        "\n",
        "convert_items(sample_en_zh_data,\n",
        "             convert_contexts=False, convert_answers=False)\n",
        "# print_json(\"Converted en-zh items\", sample_en_zh_data[:2])"
      ],
      "metadata": {
        "id": "Cm0ZMUkPZyyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a Function to Merge Items\n",
        "\n"
      ],
      "metadata": {
        "id": "QHjKClQVLd5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mergeable_item(item, context_version, question_version):\n",
        "    return {\n",
        "        'title': {context_version: item['title']},\n",
        "        'paragraphs': [{\n",
        "            'context': {context_version: paragraph['context']},\n",
        "            'qas': [{\n",
        "                'id': qa['id'],\n",
        "                'question': {question_version: qa['question']},\n",
        "                'answers': {context_version: qa['answers']},\n",
        "            } for qa in paragraph['qas']]\n",
        "        } for paragraph in item['paragraphs']]\n",
        "    }\n",
        "\n",
        "\n",
        "# Example usage\n",
        "print_json(\n",
        "    \"Original:\",\n",
        "    sample_zh_en_data_item)\n",
        "print_json(\n",
        "    \"Mergeable:\",\n",
        "    make_mergeable_item(sample_zh_en_data_item, 'zh_tw', 'en'))"
      ],
      "metadata": {
        "id": "ltaGNLfqOXbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_item(mergeable_item_1, mergeable_item_2):\n",
        "    paragraphs_map = {}\n",
        "    for paragraph in mergeable_item_1['paragraphs'] + mergeable_item_2['paragraphs']:\n",
        "        paragraph_id = paragraph['qas'][0]['id']\n",
        "        if paragraph_id not in paragraphs_map:\n",
        "            paragraphs_map[paragraph_id] = {\n",
        "                'context': {},\n",
        "                'qas_map': {},\n",
        "            }\n",
        "        paragraphs_map[paragraph_id]['context'] = {\n",
        "            **paragraphs_map[paragraph_id]['context'],\n",
        "            **paragraph['context']\n",
        "        }\n",
        "\n",
        "        qas_map = paragraphs_map[paragraph_id]['qas_map']\n",
        "        for qa in paragraph['qas']:\n",
        "            qa_id = qa['id']\n",
        "            if qa_id not in qas_map:\n",
        "                qas_map[qa_id] = {\n",
        "                    'id': qa_id,\n",
        "                    'question': {},\n",
        "                    'answers': {}\n",
        "                }    \n",
        "            qas_map[qa_id] = {\n",
        "                **qas_map[qa_id],\n",
        "                'question': {\n",
        "                    **qas_map[qa_id]['question'],\n",
        "                    **qa['question']\n",
        "\n",
        "                },\n",
        "                'answers': {\n",
        "                    **qas_map[qa_id]['answers'],\n",
        "                    **qa['answers']\n",
        "                }\n",
        "            }\n",
        "\n",
        "    return {\n",
        "        'title': {\n",
        "            **mergeable_item_1['title'],\n",
        "            **mergeable_item_2['title'],\n",
        "        },\n",
        "        'paragraphs': [{\n",
        "            'context': paragraph['context'],\n",
        "            'qas': [qa for qa in paragraph['qas_map'].values()]\n",
        "        } for paragraph in paragraphs_map.values()]\n",
        "    }\n",
        "\n",
        "\n",
        "# Example usage\n",
        "print_json(\n",
        "    \"Merged:\",\n",
        "    merge_item(\n",
        "        make_mergeable_item(sample_en_zh_data_item, 'en', 'zh_tw'),\n",
        "        make_mergeable_item(sample_zh_en_data_item, 'zh_tw', 'en')\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "WzMOPm47ZV3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_items(list_of_items_and_info):\n",
        "    merged_items = {}\n",
        "    for items, context_version, question_version in list_of_items_and_info:\n",
        "        for item in items:\n",
        "            # Take the ID of the first question as the ID of the item\n",
        "            item_id = item['paragraphs'][0]['qas'][0]['id']\n",
        "            mergeable_item = make_mergeable_item(\n",
        "                item, context_version, question_version)\n",
        "            if item_id not in merged_items:\n",
        "                merged_items[item_id] = mergeable_item\n",
        "            else:\n",
        "                merged_items[item_id] = merge_item(\n",
        "                    merged_items[item_id],\n",
        "                    mergeable_item\n",
        "                )\n",
        "    return list(merged_items.values())\n",
        "\n",
        "\n",
        "# Sample usage\n",
        "sample_merged_items = merge_items([\n",
        "    (sample_zh_zh_data, 'zh_tw', 'zh_tw'),\n",
        "    (sample_en_zh_data, 'en', 'zh_tw'),\n",
        "    (sample_zh_en_data, 'zh_tw', 'en'),\n",
        "])\n",
        "print_json(\"Sample merged items:\", sample_merged_items[:3])\n",
        "print(\"Sample zh-zh items count:\", len(sample_zh_zh_data))\n",
        "print(\"Sample en-zh items count:\", len(sample_en_zh_data))\n",
        "print(\"Sample zh-en items count:\", len(sample_zh_en_data))\n",
        "print(\"Sample merged items count:\", len(sample_merged_items))\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "display(pd.DataFrame.from_dict([\n",
        "    {\n",
        "        'en title': item['title'].get('en'),\n",
        "        'zh_tw title': item['title'].get('zh_tw'),\n",
        "    } for item in sample_merged_items\n",
        "], orient='columns'))"
      ],
      "metadata": {
        "id": "hxX9Nw4cSZDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert, Merge and Save!"
      ],
      "metadata": {
        "id": "ca7dqj4yd5Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "output_dir = '/content/outputs'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Processing dev data...\")\n",
        "dev_zh_zh_data = load_json_file(\"dev-context-zh-question-zh.json\")['data']\n",
        "dev_zh_en_data = load_json_file(\"dev-context-zh-question-en.json\")['data']\n",
        "dev_en_zh_data = load_json_file(\"dev-context-en-question-zh.json\")['data']\n",
        "convert_items(dev_zh_zh_data)\n",
        "convert_items(dev_zh_en_data,\n",
        "              convert_questions=False)\n",
        "convert_items(dev_en_zh_data,\n",
        "              convert_contexts=False, convert_answers=False)\n",
        "merged_dev_data = merge_items([\n",
        "    (dev_zh_zh_data, 'zh_tw', 'zh_tw'),\n",
        "    (dev_zh_en_data, 'zh_tw', 'en'),\n",
        "    (dev_en_zh_data, 'en', 'zh_tw'),\n",
        "])\n",
        "print(f\"Converted and merged into {len(merged_dev_data)} rows.\")\n",
        "\n",
        "output_filename = output_dir + \"/\" + \"dev-en-zh_tw.json\"\n",
        "with open(output_filename, \"w\") as outfile:\n",
        "    json.dump(merged_dev_data, outfile, indent=2, ensure_ascii=False)\n",
        "print(f\"Written to {output_filename}.\")"
      ],
      "metadata": {
        "id": "LbcR9WxSgy4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing test data...\")\n",
        "test_zh_zh_data = load_json_file(\"test-context-zh-question-zh.json\")['data']\n",
        "test_zh_en_data = load_json_file(\"test-context-zh-question-en.json\")['data']\n",
        "test_en_zh_data = load_json_file(\"test-context-en-question-zh.json\")['data']\n",
        "convert_items(test_zh_zh_data)\n",
        "convert_items(test_zh_en_data,\n",
        "              convert_questions=False)\n",
        "convert_items(test_en_zh_data,\n",
        "              convert_contexts=False, convert_answers=False)\n",
        "merged_test_data = merge_items([\n",
        "    (test_zh_zh_data, 'zh_tw', 'zh_tw'),\n",
        "    (test_zh_en_data, 'zh_tw', 'en'),\n",
        "    (test_en_zh_data, 'en', 'zh_tw'),\n",
        "])\n",
        "print(f\"Converted and merged into {len(merged_test_data)} rows.\")\n",
        "\n",
        "output_filename = output_dir + \"/\" + \"test-en-zh_tw.json\"\n",
        "with open(output_filename, \"w\") as outfile:\n",
        "    json.dump(merged_test_data, outfile, indent=2, ensure_ascii=False)\n",
        "print(f\"Written to {output_filename}.\")"
      ],
      "metadata": {
        "id": "ZXhxYV19j3Kl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}